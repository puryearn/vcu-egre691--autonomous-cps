{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful to have\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Need for messing with the Fashion MNIST dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Models to MNIST Fashion Data Set\n",
    "This exercise will show you how to use TF to build a deep NN model that classifies elements of the Fashion MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_ds = keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist_ds.load_data()\n",
    "# From tutorial code - here are the names of the labels\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(X_train[0,:,:], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0}...or, '{1}' \".format(y_train[0], class_names[y_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: NNs need to have data scaled between $[0,1]$ or $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a few of them...\n",
    "plt.figure(figsize=(8,10))\n",
    "num = 5\n",
    "idxs = np.random.choice(X_train.shape[0], num)\n",
    "i = 1\n",
    "for idx in idxs:\n",
    "    plt.subplot(1,num,i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[idx], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[idx]])\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, let's convert the labels into one-hot encoding!\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, num_classes=len(class_names))\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes=len(class_names))\n",
    "rand_idx = np.random.randint(y_train.shape[0])\n",
    "# Example:\n",
    "print(\"Original integer: {0}\\nAs one-hot vector: {1}\".format(y_train[rand_idx], y_train_onehot[rand_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build up a model with the Tensorflow's `keras.Sequential` python API.\n",
    "There are several [layer types](https://www.tensorflow.org/api_docs/python/tf/keras/layers) we can use.\n",
    "To start, let's build a standard multi-layer perceptron, since we know theoretically all we need is a single hidden layer to approximate any continuous function.\n",
    "\n",
    "**Note: MLPs do not operate on 2d data!**\n",
    "We need to add a pass through later called `Flatten` to convert the 28x28 images into a 784 dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = X_train[0].shape\n",
    "num_elements = img_shape[0]*img_shape[1]\n",
    "print(\"An image is a vector with {0} x {1} = {2} elements\".format(img_shape[0], img_shape[1], num_elements))\n",
    "fashion_classifier_model = keras.Sequential()\n",
    "# \"Dense\" is the same as \"Fully Connected\"\n",
    "fashion_classifier_model.add(Flatten(input_shape=img_shape))\n",
    "fashion_classifier_model.add(Dense(int(num_elements / 2), activation='relu'))\n",
    "fashion_classifier_model.add(Dense(10, activation='softmax')) # These are 10 logits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our model really outputs with some image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fashion_classifier_model.predict(X_train[0:1]))\n",
    "print(y_train_onehot[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is built, now you need to pick a [loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses). \n",
    "The categories are represented with integers, so we will need to use Categorical Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the end-to-end optimization structure\n",
    "fashion_classifier_model.compile(optimizer='adam',\n",
    "                                loss=loss_func,\n",
    "                                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We invoke the fitting process: Graident Descent!\n",
    "fashion_classifier_model.fit(X_train, y_train_onehot, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you need to evaluate on the test set to see how you did!\n",
    "fashion_classifier_model.evaluate(X_test, y_test_onehot, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! But let's look at the model structure. How many weights do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fire up a prediction\n",
    "test_img = X_test[0:1]\n",
    "print(\"Array of scores - we can consider each value a confidence.\")\n",
    "pred = fashion_classifier_model.predict(test_img)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extract the most likely class, we take the argmax!\n",
    "pred_idx = np.argmax(fashion_classifier_model.predict(test_img))\n",
    "print(\"We predicted input image as {0} with confidence {1}\".format(class_names[pred_idx], pred[0][pred_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional NN Model\n",
    "In this example, we swap out MLP for CNNs. They are generally more efficient on 2D data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to reshape the data, since convolutional layers are expecting images with channels.\n",
    "X_train_cnn = X_train.reshape(60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_classifier_cnnmodel = keras.Sequential()\n",
    "# Convolutional networks couple Convolution layers with pooling to boost efficiency.\n",
    "fashion_classifier_cnnmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "fashion_classifier_cnnmodel.add(MaxPool2D(pool_size=2))\n",
    "fashion_classifier_cnnmodel.add(Flatten())\n",
    "fashion_classifier_cnnmodel.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_classifier_cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME training process...just a different model.\n",
    "fashion_classifier_cnnmodel.compile(optimizer='adam',\n",
    "                                    loss=loss_func,\n",
    "                                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_classifier_cnnmodel.fit(X_train_cnn, y_train_onehot, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cnn = X_test.reshape(10000, 28, 28, 1)\n",
    "fashion_classifier_model.evaluate(X_test_cnn, y_test_onehot, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
